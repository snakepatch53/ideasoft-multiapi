Primero descargar e instalar localmente Ollama

https://ollama.com/download

luego ejecutar en terminal para descargar el modelo:

ollama pull tinyllama
ollama pull gemma:2b
ollama pull gemma3
ollama pull gpt-oss:120b-cloud